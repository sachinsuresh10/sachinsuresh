---
layout: page
title: Projects
---

<h2 style="font-family: 'Arial', sans-serif;">PROJECTS</h2>

<section>
    <ol>
        <li>
            <h4 style="font-family: 'Georgia', serif;">
                <a href="#">Data Analysis of Disasters</a>
            </h4>
            <p style="font-family: 'Georgia', serif; font-size:14px; color:black;">
                Successfully acquired and pre-processed disaster data, using Random Forest imputation to handle missing values and Principal Component Analysis (PCA) for dimensionality reduction, enhancing overall data analysis efficiency. Achieved 98.6% accuracy in disaster classification with XG Boost, demonstrating the effectiveness of advanced classification algorithms.
            </p>
            <ul style="font-family: 'Georgia', serif; font-size:14px; color:black;">
                <li>Successfully acquired and pre-processed disaster data from the database, conducting thorough data cleaning, standardization, and employing Random Forest imputation to predict and fill missing values in the dataset.</li>
                <li>Implemented Principal Component Analysis (PCA) to streamline the interpretation and analysis of numerical data by effectively reducing dimensionality, thereby enhancing overall efficiency in data analysis processes.</li>
                <li>Employed multiple linear regression and XG Boost models to predict losses in USD and deaths, with XG Boost outperforming. Utilized correlation heatmaps to analyze variable relationships. Investigated the correlation between injuries and losses in USD using linear regression modeling, achieving an adjusted R-squared of 0.8924.</li>
                <li>Highlighted the versatility of classification algorithms like Random Forest, K-Means, and XG Boost in accurately predicting country and event types in disaster classification, achieving an impressive 98.6% accuracy with XG Boost.</li>
                <li>Utilized visual representations, including bar graphs showing the occurrence frequencies of deaths, missing persons, and injuries across different events, alongside bar graphs illustrating event counts per decade, to offer clear insights into dataset distribution and trends.</li>
                <li>This analysis provides an extensive exploration of disaster data, utilizing a variety of statistical and machine learning methods to derive valuable insights and patterns.</li>
            </ul>
        </li>

         <li>
            <h4 style="font-family: 'Comic Sans MS', cursive;">
                <a href="#">Road Sign Detection using ML and IoT based rover</a>
            </h4>
            <p style="font-family: 'Comic Sans MS', cursive; font-size:14px; color:black;">
                Developed an integrated system utilising a Bluetooth-controlled rover equipped with a camera for real-time road view, transmitting live feeds to a server for OpenCV-based road sign recognition using a trained model, which autonomously commanded the rover and employed Google Text-to-Speech to inform drivers based on detected signs, demonstrating proficiency in machine learning, computer vision, IoT, and real-world deployment.
            </p>
            <ul style="font-family: 'Comic Sans MS', cursive; font-size:14px; color:black;">
                <li>Designed and implemented a Convolutional Neural Network (CNN) using Keras and TensorFlow frameworks, achieving an impressive accuracy of over 96% in classifying road signs. This project involved building a deep learning model that effectively recognized and categorized various types of traffic signs.</li>
                <li>Applied sophisticated image preprocessing techniques using OpenCV, including converting images to grayscale and performing histogram equalization. These methods enhanced the feature extraction process, enabling the model to better understand and process the visual information from the road sign images.</li>
                <li>Leveraged Keras' ImageDataGenerator for data augmentation, including random shifts, rotations, and zooms, to increase the diversity of the training data and reduce overfitting.</li>
                <li>Executed comprehensive training and validation of the CNN model, saving and loading the trained model, and using Matplotlib to plot loss and accuracy metrics over epochs for performance analysis.</li>
                <li>Efficiently handled large traffic sign datasets stored in pickle files, demonstrating proficiency in data loading, preprocessing, and transformation for machine learning applications.</li>
            </ul>
        </li>


        <li>
            <h4 style="font-family: 'Courier New', monospace;">
                <a href="#">Forecasting Economic Indicators and FTSE 100 Index</a>
            </h4>
            <p style="font-family: 'Courier New', monospace; font-size:14px; color:black;">
                Conducted comprehensive analysis and forecasting of economic indicators, employing Holt-Winters' and SARIMA models to address seasonality and trends. Developed multivariate regression models integrating key economic indicators to predict the FTSE 100 index, achieving an RMSE of 258.85, and generated actionable insights to support strategic financial decision-making.
            </p>
            <ul style="font-family: 'Courier New', monospace; font-size:14px; color:black;">
                <li>Led a comprehensive analysis of economic indicators and FTSE 100 index forecasting, employing exponential smoothing techniques for forecasting average weekly earnings, retail sales index, extraction of crude petroleum and natural gas, and turnover and orders in the manufacturing and services industries.</li>
                <li>Applied advanced statistical methods like Holt-Winters' models and SARIMA modeling for time series forecasting, demonstrating adeptness in analyzing economic data with seasonal and trend components. Achieved an Exponential Smoothing RMSE (Multiplicative Model) of 8.77.</li>
                <li>Crafted and executed multivariate regression models integrating pivotal economic indicators to predict the UK FTSE 100 share index, demonstrating prowess in statistical modeling and predictive analytics for strategic financial decision-making. Achieved an RMSE of 258.85.</li>
                <li>Generated actionable insights and recommendations through in-depth analysis of forecasted values, RMSE evaluations, and graphical illustrations, facilitating informed decision-making for the Future Stocks.</li>
                <li>Demonstrated proficiency in data manipulation and analysis using Python, including data preparation, preliminary analysis, model development, and result visualization, as evidenced by the detailed documentation and analysis provided in technical reports and accompanying Python scripts.</li>
            </ul>
        </li>


        <li>
            <h4 style="font-family: 'Verdana', sans-serif;">
                <a href="#">Data-driven Analysis of Academic Publications</a>
            </h4>
            <p style="font-family: 'Verdana', sans-serif; font-size:14px; color:black;">
                Pre-processed abstract data to create a corpus, extracting significant terms and themes through word cloud and TF-IDF analysis. Employed data cleaning, text transformation, and creation of a Document-Term Matrix (DTM) to ensure dataset readiness and cleanliness for analysis.
            </p>
            <ul style="font-family: 'Verdana', sans-serif; font-size:14px; color:black;">
                <li>Utilized Latent Dirichlet Allocation (LDA) to identify distinct topics within the dataset, determining optimal topic numbers and exploring topic evolution across time and journals.</li>
                <li>Developed a multiple regression model to predict the number of citations for new abstract submissions, offering insights into factors influencing citation impact, with an R-squared of 0.616.</li>
                <li>Developed classification models for predicting journal categories and explored word associations, revealing common co-occurrences and potential trends.</li>
                <li>Identified data clusters, revealing unique features through top words, and applied PCA for 2D visualization, enhancing understanding of abstract patterns.</li>
            </ul>
        </li>

        

       
        <li>
            <h4 style="font-family: 'Trebuchet MS', sans-serif;">
                <a href="#">Shortest Route Finder using Dijkstra's Algorithm for Rail Networks</a>
            </h4>
            <p style="font-family: 'Trebuchet MS', sans-serif; font-size:14px; color:black;">
                This project involves developing a Python script that utilizes Dijkstra's algorithm to determine the shortest paths within a given rail network. The algorithm calculates the shortest path from a specified starting station to all other stations in the network. Dijkstra's algorithm is an efficient method for finding the shortest paths between nodes in a graph, particularly when all edge weights are non-negative.
            </p>
            <ul style="font-family: 'Trebuchet MS', sans-serif; font-size:14px; color:black;">
                <li>Implemented Dijkstra's algorithm in Python to find the shortest paths between nodes in a graph, specifically for navigating a rail network.</li>
                <li>Utilized a dictionary-based representation of the network where keys represent stations and values represent neighboring stations with respective travel times.</li>
                <li>Developed functions dijkstra() and get_shortest_path() to compute the shortest path and associated travel time between a specified starting station and destination station.</li>
                <li>Incorporated a priority queue (using heapq) for efficient node selection based on current shortest paths during algorithm execution.</li>
                <li>Validated and tested the implementation on various networks to ensure correctness and efficiency, providing clear outputs detailing the shortest path and time between any given pair of stations.</li>
            </ul>
        </li>
    </ol>
</section>
